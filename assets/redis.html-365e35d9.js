import{_ as t,p as r,q as l,R as e,t as s,a1 as a}from"./framework-96b046e1.js";const n={},d=a('<h1 id="redis" tabindex="-1"><a class="header-anchor" href="#redis" aria-hidden="true">#</a> Redis</h1><h2 id="简介" tabindex="-1"><a class="header-anchor" href="#简介" aria-hidden="true">#</a> 简介</h2><p>Redis诞生于2009年全称是Remote Dictionary Server，远程词典服务器，是一个基于内存的键值型NoSQL数据库。</p><h2 id="特征" tabindex="-1"><a class="header-anchor" href="#特征" aria-hidden="true">#</a> 特征</h2><p>特征：<br> 键值（key-value）型，value支持多种不同数据结构，功能丰富<br> 单线程，每个命令具备原子性<br> 低延迟，速度快（基于内存、IO多路复用、良好的编码）。<br> 支持数据持久化<br> 支持主从集群、分片集群<br> 支持多语言客户端</p><h2 id="数据结构" tabindex="-1"><a class="header-anchor" href="#数据结构" aria-hidden="true">#</a> 数据结构</h2><p>redis是一个key-value的数据库，key一般是String类型，不过value的类型多种多样：</p><h3 id="key的结构" tabindex="-1"><a class="header-anchor" href="#key的结构" aria-hidden="true">#</a> key的结构</h3><p>Redis的key允许有多个单词形成层级结构，多个单词之间用&#39;:&#39;隔开，格式如下：<br> 项目名:业务名:类型:id</p><h3 id="string" tabindex="-1"><a class="header-anchor" href="#string" aria-hidden="true">#</a> String</h3><p>String类型，也就是字符串类型，是Redis中最简单的存储类型。<br> 其value是字符串，不过根据字符串的格式不同，又可以分为3类：</p><ul><li>string：普通字符串</li><li>int：整数类型，可以做自增、自减操作</li><li>float：浮点类型，可以做自增、自减操作</li></ul><p>不管是哪种格式，底层都是字节数组形式存储，只不过是编码方式不同。字符串类型的最大空间不能超过512m.</p><h3 id="string类型的常见命令" tabindex="-1"><a class="header-anchor" href="#string类型的常见命令" aria-hidden="true">#</a> String类型的常见命令</h3><p>String的常见命令有：<br> SET：添加或者修改已经存在的一个String类型的键值对<br> GET：根据key获取String类型的value<br> MSET：批量添加多个String类型的键值对<br> MGET：根据多个key获取多个String类型的value<br> INCR：让一个整型的key自增1<br> INCRBY:让一个整型的key自增并指定步长，例如：incrby num 2 让num值自增2<br> INCRBYFLOAT：让一个浮点类型的数字自增并指定步长<br> SETNX：添加一个String类型的键值对，前提是这个key不存在，否则不执行<br> SETEX：添加一个String类型的键值对，并且指定有效期</p><h3 id="hash类型" tabindex="-1"><a class="header-anchor" href="#hash类型" aria-hidden="true">#</a> Hash类型</h3><p>Hash类型，也叫散列，其value是一个无序字典，类似于Java中的HashMap结构。</p><h3 id="hash类型的常见命令" tabindex="-1"><a class="header-anchor" href="#hash类型的常见命令" aria-hidden="true">#</a> Hash类型的常见命令</h3><p>Hash的常见命令有：<br> HSET key field value：添加或者修改hash类型key的field的值<br> HGET key field：获取一个hash类型key的field的值<br> HMSET：批量添加多个hash类型key的field的值<br> HMGET：批量获取多个hash类型key的field的值<br> HGETALL：获取一个hash类型的key中的所有的field和value<br> HKEYS：获取一个hash类型的key中的所有的field<br> HVALS：获取一个hash类型的key中的所有的value<br> HINCRBY:让一个hash类型key的字段值自增并指定步长<br> HSETNX：添加一个hash类型的key的field值，前提是这个field不存在，否则不执行</p><h3 id="list类型" tabindex="-1"><a class="header-anchor" href="#list类型" aria-hidden="true">#</a> List类型</h3><p>Redis中的List类型与Java中的LinkedList类似，可以看做是一个双向链表结构。既可以支持正向检索和也可以支持反向检索。</p><p>特征也与LinkedList类似：</p><ul><li>有序</li><li>元素可以重复</li><li>插入和删除快</li><li>查询速度一般<br> 常用来存储一个有序数据，例如：朋友圈点赞列表，评论列表等。</li></ul><h3 id="list类型的常见命令" tabindex="-1"><a class="header-anchor" href="#list类型的常见命令" aria-hidden="true">#</a> List类型的常见命令</h3><p>List的常见命令有：</p><ul><li>LPUSH key element ... ：向列表左侧插入一个或多个元素</li><li>LPOP key：移除并返回列表左侧的第一个元素，没有则返回nil</li><li>RPUSH key element ... ：向列表右侧插入一个或多个元素</li><li>RPOP key：移除并返回列表右侧的第一个元素</li><li>LRANGE key star end：返回一段角标范围内的所有元素</li><li>BLPOP和BRPOP：与LPOP和RPOP类似，只不过在没有元素时等待指定时间，而不是直接返回nil</li></ul><p>如何利用List结构模拟一个栈?<br> 入口和出口在同一边<br> 如何利用List结构模拟一个队列?<br> 入口和出口在不同边<br> 如何利用List结构模拟一个阻塞队列?<br> 入口和出口在不同边<br> 出队时采用BLPOP或BRPOP</p><h3 id="set类型" tabindex="-1"><a class="header-anchor" href="#set类型" aria-hidden="true">#</a> Set类型</h3><p>Redis的Set结构与Java中的HashSet类似，可以看做是一个value为null的HashMap。因为也是一个hash表，因此具备与HashSet类似的特征：<br> 无序<br> 元素不可重复<br> 查找快<br> 支持交集、并集、差集等功能</p><h3 id="set类型的常见命令" tabindex="-1"><a class="header-anchor" href="#set类型的常见命令" aria-hidden="true">#</a> Set类型的常见命令</h3><p>Set的常见命令有：</p><ul><li>SADD key member ... ：向set中添加一个或多个元素</li><li>SREM key member ... : 移除set中的指定元素</li><li>SCARD key： 返回set中元素的个数</li><li>SISMEMBER key member：判断一个元素是否存在于set中</li><li>SDIFF key1 key2 ... ：求key1与key2的差集</li><li>SUNION key1 key2 ..：求key1和key2的并集</li><li>SMEMBERS：获取set中的所有元素</li><li>SINTER key1 key2 ... ：求key1与key2的交集</li></ul><h3 id="sortedset类型" tabindex="-1"><a class="header-anchor" href="#sortedset类型" aria-hidden="true">#</a> SortedSet类型</h3><p>Redis的SortedSet是一个可排序的set集合，与Java中的TreeSet有些类似，但底层数据结构却差别很大。SortedSet中的每一个元素都带有一个score属性，可以基于score属性对元素排序，底层的实现是一个跳表（SkipList）加 hash表。</p><p>SortedSet具备下列特性：<br> 可排序<br> 元素不重复<br> 查询速度快<br> 因为SortedSet的可排序特性，经常被用来实现排行榜这样的功能。</p><h3 id="sortedset类型的常见命令" tabindex="-1"><a class="header-anchor" href="#sortedset类型的常见命令" aria-hidden="true">#</a> SortedSet类型的常见命令</h3><p>SortedSet的常见命令有：<br> ZADD key score member：添加一个或多个元素到sorted set ，如果已经存在则更新其score值<br> ZREM key member：删除sorted set中的一个指定元素<br> ZSCORE key member : 获取sorted set中的指定元素的score值<br> ZRANK key member：获取sorted set 中的指定元素的排名<br> ZCARD key：获取sorted set中的元素个数<br> ZCOUNT key min max：统计score值在给定范围内的所有元素的个数<br> ZINCRBY key increment member：让sorted set中的指定元素自增，步长为指定的increment值<br> ZRANGE key min max：按照score排序后，获取指定排名范围内的元素<br> ZRANGEBYSCORE key min max：按照score排序后，获取指定score范围内的元素<br> ZDIFF、ZINTER、ZUNION：求差集、交集、并集<br> 注意：所有的排名默认都是升序，如果要降序则在命令的Z后面添加REV即可</p><h3 id="geo数据结构" tabindex="-1"><a class="header-anchor" href="#geo数据结构" aria-hidden="true">#</a> GEO数据结构</h3><p>GEO就是Geolocation的简写形式，代表地理坐标。Redis在3.2版本中加入了对GEO的支持，允许存储地理坐标信息，帮助我们根据经纬度来检索数据。常见的命令有：<br> GEOADD：添加一个地理空间信息，包含：经度（longitude）、纬度（latitude）、值（member）<br> GEODIST：计算指定的两个点之间的距离并返回<br> GEOHASH：将指定member的坐标转为hash字符串形式并返回<br> GEOPOS：返回指定member的坐标<br> GEORADIUS：指定圆心、半径，找到该圆内包含的所有member，并按照与圆心之间的距离排序后返回。6.2以后已废弃<br> GEOSEARCH：在指定范围内搜索member，并按照与指定点之间的距离排序后返回。范围可以是圆形或矩形。6.2.新功能<br> GEOSEARCHSTORE：与GEOSEARCH功能一致，不过可以把结果存储到一个指定的key。6.2.新功能</p><blockquote><p>可用于地理位置检索</p></blockquote><h3 id="bitmap" tabindex="-1"><a class="header-anchor" href="#bitmap" aria-hidden="true">#</a> BitMap</h3><p>Redis中是利用string类型数据结构实现BitMap，因此最大上限是512M，转换为bit则是 2^32个bit位。<br> BitMap的操作命令有：<br> SETBIT：向指定位置（offset）存入一个0或1<br> GETBIT ：获取指定位置（offset）的bit值<br> BITCOUNT ：统计BitMap中值为1的bit位的数量<br> BITFIELD ：操作（查询、修改、自增）BitMap中bit数组中的指定位置（offset）的值<br> BITFIELD_RO ：获取BitMap中bit数组，并以十进制形式返回<br> BITOP ：将多个BitMap的结果做位运算（与 、或、异或）<br> BITPOS ：查找bit数组中指定范围内第一个0或1出现的位置</p><blockquote><p>可用于签到</p></blockquote><h3 id="hyperloglog" tabindex="-1"><a class="header-anchor" href="#hyperloglog" aria-hidden="true">#</a> HyperLogLog</h3>',44),p=["src"],h=e("p",null,"hyperloglog(HLL)是从Loglog算法派生的概率算法，用于确定非常大的集合的基数，而不需要存储其所有值。",-1),o=e("br",null,null,-1),c=["src"],u=e("h2",{id:"缓存",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#缓存","aria-hidden":"true"},"#"),s(" 缓存")],-1),b=e("h3",{id:"缓存穿透",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#缓存穿透","aria-hidden":"true"},"#"),s(" 缓存穿透")],-1),g=e("p",null,"缓存穿透是指客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库。",-1),m=["src"],_=a('<p>缓存穿透的解决方案有哪些？</p><ul><li>缓存null值</li><li>布隆过滤</li><li>增强id的复杂度，避免被猜测id规律</li><li>做好数据的基础格式校验</li><li>加强用户权限校验</li><li>做好热点参数的限流</li></ul><h3 id="缓存雪崩" tabindex="-1"><a class="header-anchor" href="#缓存雪崩" aria-hidden="true">#</a> 缓存雪崩</h3><p>缓存雪崩是指在同一时段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力。<br> 解决方案：<br> 给不同的Key的TTL添加随机值<br> 利用Redis集群提高服务的可用性<br> 给缓存业务添加降级限流策略<br> 给业务添加多级缓存</p>',4),k=["src"],R=e("h3",{id:"缓存击穿",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#缓存击穿","aria-hidden":"true"},"#"),s(" 缓存击穿")],-1),y=e("p",null,"缓存击穿问题也叫热点Key问题，就是一个被高并发访问并且缓存重建业务较复杂的key突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。",-1),S=["src"],f=["src"],B=["src"],v=e("h2",{id:"什么是分布式锁",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#什么是分布式锁","aria-hidden":"true"},"#"),s(" 什么是分布式锁")],-1),L=e("p",null,"分布式锁：满足分布式系统或集群模式下多进程可见并且互斥的锁。",-1),O=["src"],T=e("h3",{id:"分布式锁的实现",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#分布式锁的实现","aria-hidden":"true"},"#"),s(" 分布式锁的实现")],-1),E=["src"],D=e("h3",{id:"基于redis的分布式锁",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#基于redis的分布式锁","aria-hidden":"true"},"#"),s(" 基于Redis的分布式锁")],-1),w=["src"],x=e("h3",{id:"redisson",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#redisson","aria-hidden":"true"},"#"),s(" Redisson")],-1),I=e("p",null,"Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务，其中就包含了各种分布式锁的实现。",-1),N=["src"],$=e("h2",{id:"消息队列-message-queue",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#消息队列-message-queue","aria-hidden":"true"},"#"),s(" 消息队列（Message Queue）")],-1),A=["src"],P=e("h3",{id:"基于list结构模拟消息队列",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#基于list结构模拟消息队列","aria-hidden":"true"},"#"),s(" 基于List结构模拟消息队列")],-1),H=["src"],Z=["src"],G=e("h3",{id:"基于pubsub的消息队列",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#基于pubsub的消息队列","aria-hidden":"true"},"#"),s(" 基于PubSub的消息队列")],-1),C=e("p",null,"PubSub（发布订阅）是Redis2.0版本引入的消息传递模型。顾名思义，消费者可以订阅一个或多个channel，生产者向对应channel发送消息后，所有订阅者都能收到相关消息。",-1),q=["src"],F=["src"],M=e("h3",{id:"基于stream的消息队列",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#基于stream的消息队列","aria-hidden":"true"},"#"),s(" 基于Stream的消息队列")],-1),K=["src"],z=["src"],J=["src"],U=e("h2",{id:"多级缓存",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#多级缓存","aria-hidden":"true"},"#"),s(" 多级缓存")],-1),j=e("h3",{id:"传统缓存问题",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#传统缓存问题","aria-hidden":"true"},"#"),s(" 传统缓存问题")],-1),Q=["src"],V=e("h3",{id:"多级缓存方案",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#多级缓存方案","aria-hidden":"true"},"#"),s(" 多级缓存方案")],-1),W=["src"],Y=a('<h3 id="本地进程缓存" tabindex="-1"><a class="header-anchor" href="#本地进程缓存" aria-hidden="true">#</a> 本地进程缓存</h3><p>Caffeine是一个基于Java8开发的，提供了近乎最佳命中率的高性能的本地缓存库。目前Spring内部的缓存使用的就是Caffeine。GitHub地址：https://github.com/ben-manes/caffeine</p><h2 id="持久化" tabindex="-1"><a class="header-anchor" href="#持久化" aria-hidden="true">#</a> 持久化</h2><h3 id="rdb" tabindex="-1"><a class="header-anchor" href="#rdb" aria-hidden="true">#</a> RDB</h3><p>RDB的实现方式为，在指定时间将当前时刻内存中的数据生成一个快照文件（.rdb文件，默认为dump.rdb），并将这个快照文件保存到磁盘上。这样，即使redis宕机了，下次重启时也可以通过读取这个快照文件来恢复数据。</p><p>rdb文件默认文件名为dump.rdb，是在配置文件中配置的如果我们想要修改这个名字可以修改下面的配置</p><p>触发生成rdb快照文件的方式主要有五种：配置文件自动触发、执行save命令、执行bgsave命令、执行shutdown命令、执行flushall命令。</p><h3 id="生成方式" tabindex="-1"><a class="header-anchor" href="#生成方式" aria-hidden="true">#</a> 生成方式</h3><p>1.配置文件自动触发</p><p>redis默认的配置文件redis.conf中，有一个自动触发rdb持久化的配置：</p>',10),X=["src"],ee=e("p",null,"2.执行save命令",-1),ie=e("p",null,"save命令是一个同步操作，执行该命令后，RDB持久化是在主进程中进行的，这样会阻塞当前redis服务，直到RDB持久化完成后，客户端才能正常连接redis服务",-1),se=e("br",null,null,-1),ae=e("br",null,null,-1),te=["src"],re=e("p",null,[s("4.执行shutdown命令"),e("br"),s(" 这种触发方式比较简单，只需要在客户端执行shutdown命令即可")],-1),le=e("p",null,"5.执行flushall命令",-1),ne=e("p",null,"flushall命令是清空redis内存中的数据，并且同时清空dump.rdb文件。所以这个命令就相当于删库跑路，此处只是说明该命令会触发rdb，实际使用中千万不要执行。",-1),de=e("p",null,"如果之前没有dump.rdb文件，则执行flushall命令后，会生成一个dump.rdb文件",-1),pe=e("p",null,"如果之前已经存在dump.rdb文件，并且里面也存在数据，那么执行flushall命令后，会将原来dump.rdb文件中的内容清空。",-1),he=e("h3",{id:"rdb文件重写",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#rdb文件重写","aria-hidden":"true"},"#"),s(" RDB文件重写")],-1),oe=["src"],ce=e("h3",{id:"rdb的缺点",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#rdb的缺点","aria-hidden":"true"},"#"),s(" RDB的缺点")],-1),ue=e("p",null,[s("RDB执行间隔时间长，两次RDB之间写入数据有丢失的风险"),e("br"),s(" fork子进程、压缩、写出RDB文件都比较耗时")],-1),be=e("h3",{id:"aof",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#aof","aria-hidden":"true"},"#"),s(" AOF")],-1),ge=e("p",null,"AOF是redis提供的另一种数据持久化方式，它会记录客户端对redis服务端的每一次写操作，并将这些写操作以redis协议追加保存到后缀为aof的文件末尾。在redis服务器重启时，会读取并加载aof文件，达到恢复数据的目的。",-1),me=e("p",null,"aof持久化方式redis是默认不开启的，我们可以通过配置文件开启aof持久化方式",-1),_e=["src"],ke=a('<p>appendonly的值默认为no，改为yes即可开启aof持久化方式。AOF的默认文件名为appendonly.aof，也可通过appendfilename配置修改。</p><p>AOF的三种写入策略</p><ol><li>appendfsync always</li></ol><p>客户端对redis服务器的每次写操作都写入AOF日志文件。这种方式是最安全的方式，但每次写操作都进行一次磁盘IO，非常影响redis的性能，所以一般不使用这种方式。</p><ol start="2"><li>appendfsync everysec</li></ol><p>每秒刷新一次缓冲区中的数据到AOF文件。这种方式是redis默认使用的策略，是考虑数据完整性和性能的这种方案，理论上，这种方式最多只会丢失1秒内的数据。</p><ol start="3"><li>appendfsync no</li></ol><p>redis服务器不负责将数据写入到AOF文件中，而是直接交给操作系统去判断什么时候写入。这种方式是最快的一种策略，但丢失数据的可能性非常大，因此也是不推荐使用的。</p><h3 id="aof文件重写" tabindex="-1"><a class="header-anchor" href="#aof文件重写" aria-hidden="true">#</a> AOF文件重写</h3><p>既然AOF是通过日志追加的方式来存储redis的写指令，那么当我们对同一个key做多次写操作时，就会产生大量针对同一个key操作的日志指令，导致AOF文件会变得非常大，恢复数据的时候会变得非常慢。因此，redis提供了重写机制来解决这个问题。redis通过重写AOF文件，保存的只是恢复数据的最小指令集。</p><p>我们可以通过下面命令手动触发重写：bgrewriteaof。</p>',11),Re=["src"],ye=e("h3",{id:"rdb和aof对比",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#rdb和aof对比","aria-hidden":"true"},"#"),s(" RDB和AOF对比")],-1),Se=["src"],fe=["src"],Be=e("h2",{id:"集群",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#集群","aria-hidden":"true"},"#"),s(" 集群")],-1),ve=e("h3",{id:"单点redis的问题",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#单点redis的问题","aria-hidden":"true"},"#"),s(" 单点Redis的问题")],-1),Le=["src"],Oe=e("h3",{id:"redis主从",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#redis主从","aria-hidden":"true"},"#"),s(" Redis主从")],-1),Te=["src"],Ee=e("h3",{id:"主从数据同步原理",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#主从数据同步原理","aria-hidden":"true"},"#"),s(" 主从数据同步原理")],-1),De=e("p",null,"全量同步",-1),we=e("p",null,[s("主从第一次建立连接时，会执行"),e("strong",null,"全量同步"),s("，将master节点的所有数据都拷贝给slave节点，流程：")],-1),xe=["src"],Ie=["src"],Ne=["src"],$e=a("<p>完整流程描述：</p><ul><li>slave节点请求增量同步</li><li>master节点判断replid，发现不一致，拒绝增量同步</li><li>master将完整内存数据生成RDB，发送RDB到slave</li><li>slave清空本地数据，加载master的RDB</li><li>master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave</li><li>slave执行接收到的命令，保持与master之间的同步</li></ul><p>增量同步</p><p>全量同步需要先做RDB，然后将RDB文件通过网络传输个slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做<strong>增量同步</strong>。</p>",4),Ae=["src"],Pe=e("p",null,"repl_backlog原理",-1),He=["src"],Ze=e("h3",{id:"主从同步优化",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#主从同步优化","aria-hidden":"true"},"#"),s(" 主从同步优化")],-1),Ge=["src"],Ce=e("h3",{id:"全量同步和增量同步区别",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#全量同步和增量同步区别","aria-hidden":"true"},"#"),s(" 全量同步和增量同步区别")],-1),qe=["src"],Fe=e("h3",{id:"redis哨兵",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#redis哨兵","aria-hidden":"true"},"#"),s(" Redis哨兵")],-1),Me=e("p",null,"Redis提供了哨兵（Sentinel）机制来实现主从集群的自动故障恢复。",-1),Ke=["src"],ze=a('<p>哨兵的作用如下：</p><ul><li><strong>监控</strong>：Sentinel 会不断检查您的master和slave是否按预期工作</li><li><strong>自动故障恢复</strong>：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主</li><li><strong>通知</strong>：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端</li></ul><h3 id="集群监控原理" tabindex="-1"><a class="header-anchor" href="#集群监控原理" aria-hidden="true">#</a> 集群监控原理</h3><p>Sentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令：</p><p>•主观下线：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例<strong>主观下线</strong>。</p><p>•客观下线：若超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例<strong>客观下线</strong>。quorum值最好超过Sentinel实例数量的一半。</p>',6),Je=["src"],Ue=a('<h3 id="集群故障恢复原理" tabindex="-1"><a class="header-anchor" href="#集群故障恢复原理" aria-hidden="true">#</a> 集群故障恢复原理</h3><p>一旦发现master故障，sentinel需要在salve中选择一个作为新的master，选择依据是这样的：</p><ul><li>首先会判断slave节点与master节点断开时间长短，如果超过指定值（down-after-milliseconds * 10）则会排除该slave节点</li><li>然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举</li><li>如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高</li><li>最后是判断slave节点的运行id大小，越小优先级越高。</li></ul><p>当选出一个新的master后，该如何实现切换呢？</p><p>流程如下：</p><ul><li>sentinel给备选的slave1节点发送slaveof no one命令，让该节点成为master</li><li>sentinel给所有其它slave发送slaveof 192.168.150.101 7002 命令，让这些slave成为新master的从节点，开始从新的master上同步数据。</li><li>最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点</li></ul>',6),je=["src"],Qe=a('<p>Sentinel的三个作用是什么？</p><ul><li>监控</li><li>故障转移</li><li>通知</li></ul><p>Sentinel如何判断一个redis实例是否健康？</p><ul><li>每隔1秒发送一次ping命令，如果超过一定时间没有相向则认为是主观下线</li><li>如果大多数sentinel都认为实例主观下线，则判定服务下线</li></ul><p>故障转移步骤有哪些？</p><ul><li>首先选定一个slave作为新的master，执行slaveof no one</li><li>然后让所有节点都执行slaveof 新master</li><li>修改故障节点配置，添加slaveof 新master</li></ul><h3 id="redis分片集群" tabindex="-1"><a class="header-anchor" href="#redis分片集群" aria-hidden="true">#</a> Redis分片集群</h3><p>主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决：</p><ul><li>海量数据存储问题</li><li>高并发写的问题</li></ul><p>使用分片集群可以解决上述问题，如图:</p>',10),Ve=["src"],We=e("p",null,"分片集群特征：",-1),Ye=e("ul",null,[e("li",null,"集群中有多个master，每个master保存不同数据"),e("li",null,"每个master都可以有多个slave节点"),e("li",null,"master之间通过ping监测彼此健康状态"),e("li",null,"客户端请求可以访问集群任意节点，最终都会被转发到正确节点")],-1),Xe=e("h3",{id:"散列插槽",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#散列插槽","aria-hidden":"true"},"#"),s(" 散列插槽")],-1),ei=["src"],ii=a('<p>Redis如何判断某个key应该在哪个实例？</p><ul><li>将16384个插槽分配到不同的实例</li><li>根据key的有效部分计算哈希值，对16384取余</li><li>余数作为插槽，寻找插槽所在实例即可</li></ul><p>如何将同一类数据固定的保存在同一个Redis实例？</p><ul><li>这一类数据使用相同的有效部分，例如key都以{typeId}为前缀</li></ul><h2 id="最佳实战" tabindex="-1"><a class="header-anchor" href="#最佳实战" aria-hidden="true">#</a> 最佳实战</h2><h3 id="redis键值设计" tabindex="-1"><a class="header-anchor" href="#redis键值设计" aria-hidden="true">#</a> Redis键值设计</h3><p>优雅的key结构</p><p>Redis的Key虽然可以自定义，但最好遵循下面的几个最佳实践约定：</p><ul><li>遵循基本格式：[业务名称]:[数据名]:[id]</li><li>长度不超过44字节</li><li>不包含特殊字符</li></ul><p>这样设计的好处：</p><ul><li>可读性强</li><li>避免key冲突</li><li>方便管理</li><li>更节省内存： key是string类型，底层编码包含int、embstr和raw三种。embstr在小于44字节使用，采用连续内存空间，内存占用更小。当字节数大于44字节时，会转为raw模式存储，在raw模式下，内存空间不是连续的，而是采用一个指针指向了另外一段内存空间，在这段空间里存储SDS内容，这样空间不连续，访问的时候性能也就会收到影响，还有可能产生内存碎片</li></ul><h3 id="拒绝bigkey" tabindex="-1"><a class="header-anchor" href="#拒绝bigkey" aria-hidden="true">#</a> 拒绝BigKey</h3><p>BigKey通常以Key的大小和Key中成员的数量来综合判定，例如：</p><ul><li>Key本身的数据量过大：一个String类型的Key，它的值为5 MB</li><li>Key中的成员数过多：一个ZSET类型的Key，它的成员数量为10,000个</li><li>Key中成员的数据量过大：一个Hash类型的Key，它的成员数量虽然只有1,000个但这些成员的Value（值）总大小为100 MB</li></ul>',14),si=["src"],ai=a(`<p>BigKey的危害</p><ul><li>网络阻塞</li><li>对BigKey执行读请求时，少量的QPS就可能导致带宽使用率被占满，导致Redis实例，乃至所在物理机变慢</li><li>数据倾斜 <ul><li>BigKey所在的Redis实例内存使用率远超其他实例，无法使数据分片的内存资源达到均衡</li></ul></li><li>Redis阻塞 <ul><li>对元素较多的hash、list、zset等做运算会耗时较旧，使主线程被阻塞</li></ul></li><li>CPU压力 <ul><li>对BigKey的数据序列化和反序列化会导致CPU的使用率飙升，影响Redis实例和本机其它应用</li></ul></li></ul><p>如何发现BigKey</p><h5 id="_1redis-cli-bigkeys" tabindex="-1"><a class="header-anchor" href="#_1redis-cli-bigkeys" aria-hidden="true">#</a> ①redis-cli --bigkeys</h5><p>利用redis-cli提供的--bigkeys参数，可以遍历分析所有key，并返回Key的整体统计信息与每个数据的Top1的big key</p><p>命令：<code>redis-cli -a 密码 --bigkeys</code></p><h5 id="_2scan扫描" tabindex="-1"><a class="header-anchor" href="#_2scan扫描" aria-hidden="true">#</a> ②scan扫描</h5><p>自己编程，利用scan扫描Redis中的所有key，利用strlen、hlen等命令判断key的长度（此处不建议使用MEMORY USAGE）</p><h5 id="_3第三方工具" tabindex="-1"><a class="header-anchor" href="#_3第三方工具" aria-hidden="true">#</a> ③第三方工具</h5><ul><li>利用第三方工具，如 Redis-Rdb-Tools 分析RDB快照文件，全面分析内存使用情况</li></ul><h5 id="_4网络监控" tabindex="-1"><a class="header-anchor" href="#_4网络监控" aria-hidden="true">#</a> ④网络监控</h5><ul><li>自定义工具，监控进出Redis的网络数据，超出预警值时主动告警</li></ul><p>如何删除BigKey</p><p>BigKey内存占用较多，即便时删除这样的key也需要耗费很长时间，导致Redis主线程阻塞，引发一系列问题。</p><ul><li><p>redis 3.0 及以下版本</p><ul><li>如果是集合类型，则遍历BigKey的元素，先逐个删除子元素，最后删除BigKey</li></ul><p>Redis 4.0以后</p></li><li><p>Redis在4.0后提供了异步删除的命令：unlink</p></li></ul><h3 id="恰当的数据类型" tabindex="-1"><a class="header-anchor" href="#恰当的数据类型" aria-hidden="true">#</a> 恰当的数据类型</h3><p>比如存储一个User对象，我们有三种存储方式：</p><h5 id="_1方式一-json字符串" tabindex="-1"><a class="header-anchor" href="#_1方式一-json字符串" aria-hidden="true">#</a> ①方式一：json字符串</h5><table><thead><tr><th style="text-align:center;">user:1</th><th style="text-align:center;">{&quot;name&quot;: &quot;Jack&quot;, &quot;age&quot;: 21}</th></tr></thead></table><p>优点：实现简单粗暴</p><p>缺点：数据耦合，不够灵活</p><h5 id="_2方式二-字段打散" tabindex="-1"><a class="header-anchor" href="#_2方式二-字段打散" aria-hidden="true">#</a> ②方式二：字段打散</h5><table><thead><tr><th style="text-align:center;">user:1:name</th><th style="text-align:center;">Jack</th></tr></thead><tbody><tr><td style="text-align:center;">user:1:age</td><td style="text-align:center;">21</td></tr></tbody></table><p>优点：可以灵活访问对象任意字段</p><p>缺点：占用空间大、没办法做统一控制</p><h5 id="_3方式三-hash-推荐" tabindex="-1"><a class="header-anchor" href="#_3方式三-hash-推荐" aria-hidden="true">#</a> ③方式三：hash（推荐）</h5><table><tr><td rowspan="2">user:1</td><td>name</td><td>jack</td></tr><tr><td>age</td><td>21</td></tr></table><p>优点：底层使用ziplist，空间占用小，可以灵活访问对象的任意字段</p><p>缺点：代码相对复杂</p><h3 id="批量处理优化" tabindex="-1"><a class="header-anchor" href="#批量处理优化" aria-hidden="true">#</a> 批量处理优化</h3><p>Redis提供了很多Mxxx这样的命令，可以实现批量插入数据，例如：</p><ul><li>mset</li><li>hmset</li></ul><p>MSET虽然可以批处理，但是却只能操作部分数据类型，因此如果有对复杂数据类型的批处理需要，建议使用Pipeline</p><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token annotation punctuation">@Test</span>
<span class="token keyword">void</span> <span class="token function">testPipeline</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// 创建管道</span>
    <span class="token class-name">Pipeline</span> pipeline <span class="token operator">=</span> jedis<span class="token punctuation">.</span><span class="token function">pipelined</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">long</span> b <span class="token operator">=</span> <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> i <span class="token operator">&lt;=</span> <span class="token number">100000</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 放入命令到管道</span>
        pipeline<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">&quot;test:key_&quot;</span> <span class="token operator">+</span> i<span class="token punctuation">,</span> <span class="token string">&quot;value_&quot;</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token comment">// 每放入1000条命令，批量执行</span>
            pipeline<span class="token punctuation">.</span><span class="token function">sync</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    <span class="token keyword">long</span> e <span class="token operator">=</span> <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;time: &quot;</span> <span class="token operator">+</span> <span class="token punctuation">(</span>e <span class="token operator">-</span> b<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="集群下的批处理" tabindex="-1"><a class="header-anchor" href="#集群下的批处理" aria-hidden="true">#</a> 集群下的批处理</h3>`,35),ti=["src"],ri=a('<h3 id="服务器端优化-持久化配置" tabindex="-1"><a class="header-anchor" href="#服务器端优化-持久化配置" aria-hidden="true">#</a> 服务器端优化-持久化配置</h3><p>Redis的持久化虽然可以保证数据安全，但也会带来很多额外的开销，因此持久化请遵循下列建议：</p><ul><li><p>用来做缓存的Redis实例尽量不要开启持久化功能</p></li><li><p>建议关闭RDB持久化功能，使用AOF持久化</p></li><li><p>利用脚本定期在slave节点做RDB，实现数据备份</p></li><li><p>设置合理的rewrite阈值，避免频繁的bgrewrite</p></li><li><p>配置no-appendfsync-on-rewrite = yes，禁止在rewrite期间做aof，避免因AOF引起的阻塞</p></li><li><p>部署有关建议：</p><ul><li>Redis实例的物理机要预留足够内存，应对fork和rewrite</li><li>单个Redis实例内存上限不要太大，例如4G或8G。可以加快fork的速度、减少主从同步、数据迁移压力</li><li>不要与CPU密集型应用部署在一起</li><li>不要与高硬盘负载应用一起部署。例如：数据库、消息队列</li></ul><h3 id="服务器端优化-慢查询优化" tabindex="-1"><a class="header-anchor" href="#服务器端优化-慢查询优化" aria-hidden="true">#</a> 服务器端优化-慢查询优化</h3><p>并不是很慢的查询才是慢查询，而是：在Redis执行时耗时超过某个阈值的命令，称为慢查询。</p></li></ul><p>慢查询的危害：由于Redis是单线程的，所以当客户端发出指令后，他们都会进入到redis底层的queue来执行，如果此时有一些慢查询的数据，就会导致大量请求阻塞，从而引起报错，所以我们需要解决慢查询问题。</p><p>慢查询的阈值可以通过配置指定：</p><p>slowlog-log-slower-than：慢查询阈值，单位是微秒。默认是10000，建议1000</p><p>慢查询会被放入慢查询日志中，日志的长度有上限，可以通过配置指定：</p><p>slowlog-max-len：慢查询日志（本质是一个队列）的长度。默认是128，建议1000</p><p>知道了以上内容之后，那么咱们如何去查看慢查询日志列表呢：</p><ul><li>slowlog len：查询慢查询日志长度</li><li>slowlog get [n]：读取n条慢查询日志</li><li>slowlog reset：清空慢查询列表</li></ul><h3 id="服务器端优化-redis内存划分和内存配置" tabindex="-1"><a class="header-anchor" href="#服务器端优化-redis内存划分和内存配置" aria-hidden="true">#</a> 服务器端优化-Redis内存划分和内存配置</h3><p>当Redis内存不足时，可能导致Key频繁被删除、响应时间变长、QPS不稳定等问题。当内存使用率达到90%以上时就需要我们警惕，并快速定位到内存占用的原因。</p><p><strong>有关碎片问题分析</strong></p><p>Redis底层分配并不是这个key有多大，他就会分配多大，而是有他自己的分配策略，比如8,16,20等等，假定当前key只需要10个字节，此时分配8肯定不够，那么他就会分配16个字节，多出来的6个字节就不能被使用，这就是我们常说的 碎片问题</p><p><strong>进程内存问题分析：</strong></p><p>这片内存，通常我们都可以忽略不计</p><p><strong>缓冲区内存问题分析：</strong></p><p>一般包括客户端缓冲区、AOF缓冲区、复制缓冲区等。客户端缓冲区又包括输入缓冲区和输出缓冲区两种。这部分内存占用波动较大，所以这片内存也是我们需要重点分析的内存问题。</p><table><thead><tr><th><strong>内存占用</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>数据内存</td><td>是Redis最主要的部分，存储Redis的键值信息。主要问题是BigKey问题、内存碎片问题</td></tr><tr><td>进程内存</td><td>Redis主进程本身运⾏肯定需要占⽤内存，如代码、常量池等等；这部分内存⼤约⼏兆，在⼤多数⽣产环境中与Redis数据占⽤的内存相⽐可以忽略。</td></tr><tr><td>缓冲区内存</td><td>一般包括客户端缓冲区、AOF缓冲区、复制缓冲区等。客户端缓冲区又包括输入缓冲区和输出缓冲区两种。这部分内存占用波动较大，不当使用BigKey，可能导致内存溢出。</td></tr></tbody></table><p>于是我们就需要通过一些命令，可以查看到Redis目前的内存分配状态：</p><ul><li>info memory：查看内存分配的情况</li></ul><p>内存缓冲区常见的有三种：</p><ul><li>复制缓冲区：主从复制的repl_backlog_buf，如果太小可能导致频繁的全量复制，影响性能。通过replbacklog-size来设置，默认1mb</li><li>AOF缓冲区：AOF刷盘之前的缓存区域，AOF执行rewrite的缓冲区。无法设置容量上限</li><li>客户端缓冲区：分为输入缓冲区和输出缓冲区，输入缓冲区最大1G且不能设置。输出缓冲区可以设置</li></ul><p>以上复制缓冲区和AOF缓冲区 不会有问题，最关键就是客户端缓冲区的问题</p><p>客户端缓冲区：指的就是我们发送命令时，客户端用来缓存命令的一个缓冲区，也就是我们向redis输入数据的输入端缓冲区和redis向客户端返回数据的响应缓存区，输入缓冲区最大1G且不能设置，所以这一块我们根本不用担心，如果超过了这个空间，redis会直接断开，因为本来此时此刻就代表着redis处理不过来了，我们需要担心的就是输出端缓冲区</p><p>我们在使用redis过程中，处理大量的big value，那么会导致我们的输出结果过多，如果输出缓存区过大，会导致redis直接断开，而默认配置的情况下， 其实他是没有大小的，这就比较坑了，内存可能一下子被占满，会直接导致咱们的redis断开，所以解决方案有两个</p><p>1、设置一个大小</p><p>2、增加我们带宽的大小，避免我们出现大量数据从而直接超过了redis的承受能力</p><h3 id="服务器端集群优化-集群还是主从" tabindex="-1"><a class="header-anchor" href="#服务器端集群优化-集群还是主从" aria-hidden="true">#</a> 服务器端集群优化-集群还是主从</h3><p>集群虽然具备高可用特性，能实现自动故障恢复，但是如果使用不当，也会存在一些问题：</p><ul><li>集群完整性问题</li><li>集群带宽问题</li><li>数据倾斜问题</li><li>客户端性能问题</li><li>命令的集群兼容性问题</li><li>lua和事务问题</li></ul><p><strong>问题1、在Redis的默认配置中，如果发现任意一个插槽不可用，则整个集群都会停止对外服务：</strong></p><p>大家可以设想一下，如果有几个slot不能使用，那么此时整个集群都不能用了，我们在开发中，其实最重要的是可用性，所以需要把如下配置修改成no，即有slot不能使用时，我们的redis集群还是可以对外提供服务<br><strong>问题2、集群带宽问题</strong></p><p>集群节点之间会不断的互相Ping来确定集群中其它节点的状态。每次Ping携带的信息至少包括：</p><ul><li>插槽信息</li><li>集群状态信息</li></ul><p>集群中节点越多，集群状态信息数据量也越大，10个节点的相关信息可能达到1kb，此时每次集群互通需要的带宽会非常高，这样会导致集群中大量的带宽都会被ping信息所占用，这是一个非常可怕的问题，所以我们需要去解决这样的问题</p><p><strong>解决途径：</strong></p><ul><li>避免大集群，集群节点数不要太多，最好少于1000，如果业务庞大，则建立多个集群。</li><li>避免在单个物理机中运行太多Redis实例</li><li>配置合适的cluster-node-timeout值</li></ul><p><strong>问题3、命令的集群兼容性问题</strong></p><p>有关这个问题咱们已经探讨过了，当我们使用批处理的命令时，redis要求我们的key必须落在相同的slot上，然后大量的key同时操作时，是无法完成的，所以客户端必须要对这样的数据进行处理，这些方案我们之前已经探讨过了，所以不再这个地方赘述了。</p><p><strong>问题4、lua和事务的问题</strong></p><p>lua和事务都是要保证原子性问题，如果你的key不在一个节点，那么是无法保证lua的执行和事务的特性的，所以在集群模式是没有办法执行lua和事务的</p><p><strong>那我们到底是集群还是主从</strong></p><p>单体Redis（主从Redis）已经能达到万级别的QPS，并且也具备很强的高可用特性。如果主从能满足业务需求的情况下，所以如果不是在万不得已的情况下，尽量不搭建Redis集群</p><h2 id="原理篇-redis数据结构" tabindex="-1"><a class="header-anchor" href="#原理篇-redis数据结构" aria-hidden="true">#</a> 原理篇-Redis数据结构</h2><h3 id="redis数据结构-动态字符串" tabindex="-1"><a class="header-anchor" href="#redis数据结构-动态字符串" aria-hidden="true">#</a> Redis数据结构-动态字符串</h3><p>我们都知道Redis中保存的Key是字符串，value往往是字符串或者字符串的集合。可见字符串是Redis中最常用的一种数据结构。</p><p>不过Redis没有直接使用C语言中的字符串，因为C语言字符串存在很多问题： 获取字符串长度的需要通过运算 非二进制安全 不可修改 Redis构建了一种新的字符串结构，称为简单动态字符串（Simple Dynamic String），简称SDS</p>',48),li=["src"],ni=["src"],di=e("h3",{id:"redis数据结构-intset",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#redis数据结构-intset","aria-hidden":"true"},"#"),s(" Redis数据结构-intset")],-1),pi=["src"],hi=["src"],oi=a('<p>小总结：</p><p>Intset可以看做是特殊的整数数组，具备一些特点：</p><ul><li>Redis会确保Intset中的元素唯一、有序</li><li>具备类型升级机制，可以节省内存空间</li><li>底层采用二分查找方式来查询</li></ul><h3 id="redis数据结构-dict" tabindex="-1"><a class="header-anchor" href="#redis数据结构-dict" aria-hidden="true">#</a> Redis数据结构-Dict</h3><p>我们知道Redis是一个键值型（Key-Value Pair）的数据库，我们可以根据键实现快速的增删改查。而键与值的映射关系正是通过Dict来实现的。 Dict由三部分组成，分别是：哈希表（DictHashTable）、哈希节点（DictEntry）、字典（Dict）</p><p>小总结：</p><p>Dict的结构：</p><ul><li>类似java的HashTable，底层是数组加链表来解决哈希冲突</li><li>Dict包含两个哈希表，ht[0]平常用，ht[1]用来rehash</li></ul><p>Dict的伸缩：</p><ul><li>当LoadFactor大于5或者LoadFactor大于1并且没有子进程任务时，Dict扩容</li><li>当LoadFactor小于0.1时，Dict收缩</li><li>扩容大小为第一个大于等于used + 1的2^n</li><li>收缩大小为第一个大于等于used 的2^n</li><li>Dict采用渐进式rehash，每次访问Dict时执行一次rehash</li><li>rehash时ht[0]只减不增，新增操作只在ht[1]执行，其它操作在两个哈希表</li></ul><h3 id="redis数据结构-ziplist" tabindex="-1"><a class="header-anchor" href="#redis数据结构-ziplist" aria-hidden="true">#</a> Redis数据结构-ZipList</h3><p>ZipList 是一种特殊的“双端链表” ，由一系列特殊编码的连续内存块组成。可以在任意一端进行压入/弹出操作, 并且该操作的时间复杂度为 O(1)。</p><p><strong>小总结：</strong></p><p><strong>ZipList特性：</strong></p><ul><li>压缩列表的可以看做一种连续内存空间的&quot;双向链表&quot;</li><li>列表的节点之间不是通过指针连接，而是记录上一节点和本节点长度来寻址，内存占用较低</li><li>如果列表数据过多，导致链表过长，可能影响查询性能</li><li>增或删较大数据时有可能发生连续更新问题</li></ul><h3 id="redis数据结构-quicklist" tabindex="-1"><a class="header-anchor" href="#redis数据结构-quicklist" aria-hidden="true">#</a> Redis数据结构-QuickList</h3><p>Redis在3.2版本引入了新的数据结构QuickList，它是一个双端链表，只不过链表中的每个节点都是一个ZipList。</p><p>为了避免QuickList中的每个ZipList中entry过多，Redis提供了一个配置项：list-max-ziplist-size来限制。 如果值为正，则代表ZipList的允许的entry个数的最大值 如果值为负，则代表ZipList的最大内存大小，分5种情况：</p><ul><li>-1：每个ZipList的内存占用不能超过4kb</li><li>-2：每个ZipList的内存占用不能超过8kb</li><li>-3：每个ZipList的内存占用不能超过16kb</li><li>-4：每个ZipList的内存占用不能超过32kb</li><li>-5：每个ZipList的内存占用不能超过64kb</li></ul><p>其默认值为 -2：</p><p>总结：</p><p>QuickList的特点：</p><ul><li>是一个节点为ZipList的双端链表</li><li>节点采用ZipList，解决了传统链表的内存占用问题</li><li>控制了ZipList大小，解决连续内存空间申请效率问题</li><li>中间节点可以压缩，进一步节省了内存</li></ul><h3 id="redis数据结构-skiplist" tabindex="-1"><a class="header-anchor" href="#redis数据结构-skiplist" aria-hidden="true">#</a> Redis数据结构-SkipList</h3><p>SkipList（跳表）首先是链表，但与传统链表相比有几点差异：<br> 元素按照升序排列存储<br> 节点可能包含多个指针，指针跨度不同。</p><p>小总结：</p><p>SkipList的特点：</p><ul><li>跳跃表是一个双向链表，每个节点都包含score和ele值</li><li>节点按照score值排序，score值一样则按照ele字典排序</li><li>每个节点都可以包含多层指针，层数是1到32之间的随机数</li><li>不同层指针到下一个节点的跨度不同，层级越高，跨度越大</li><li>增删改查效率与红黑树基本一致，实现却更简单</li></ul><h3 id="redis数据结构-redisobject" tabindex="-1"><a class="header-anchor" href="#redis数据结构-redisobject" aria-hidden="true">#</a> Redis数据结构-RedisObject</h3><p>Redis中的任意数据类型的键和值都会被封装为一个RedisObject，也叫做Redis对象，源码如下：</p><p>1、什么是redisObject： 从Redis的使用者的角度来看，⼀个Redis节点包含多个database（非cluster模式下默认是16个，cluster模式下只能是1个），而一个database维护了从key space到object space的映射关系。这个映射关系的key是string类型，⽽value可以是多种数据类型，比如： string, list, hash、set、sorted set等。我们可以看到，key的类型固定是string，而value可能的类型是多个。 ⽽从Redis内部实现的⾓度来看，database内的这个映射关系是用⼀个dict来维护的。dict的key固定用⼀种数据结构来表达就够了，这就是动态字符串sds。而value则比较复杂，为了在同⼀个dict内能够存储不同类型的value，这就需要⼀个通⽤的数据结构，这个通用的数据结构就是robj，全名是redisObject。</p>',31),ci=["src"],ui=a('<p>Redis的编码方式</p><p>Redis中会根据存储的数据类型不同，选择不同的编码方式，共包含11种不同类型：</p><table><thead><tr><th><strong>编号</strong></th><th><strong>编码方式</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>0</td><td>OBJ_ENCODING_RAW</td><td>raw编码动态字符串</td></tr><tr><td>1</td><td>OBJ_ENCODING_INT</td><td>long类型的整数的字符串</td></tr><tr><td>2</td><td>OBJ_ENCODING_HT</td><td>hash表（字典dict）</td></tr><tr><td>3</td><td>OBJ_ENCODING_ZIPMAP</td><td>已废弃</td></tr><tr><td>4</td><td>OBJ_ENCODING_LINKEDLIST</td><td>双端链表</td></tr><tr><td>5</td><td>OBJ_ENCODING_ZIPLIST</td><td>压缩列表</td></tr><tr><td>6</td><td>OBJ_ENCODING_INTSET</td><td>整数集合</td></tr><tr><td>7</td><td>OBJ_ENCODING_SKIPLIST</td><td>跳表</td></tr><tr><td>8</td><td>OBJ_ENCODING_EMBSTR</td><td>embstr的动态字符串</td></tr><tr><td>9</td><td>OBJ_ENCODING_QUICKLIST</td><td>快速列表</td></tr><tr><td>10</td><td>OBJ_ENCODING_STREAM</td><td>Stream流</td></tr></tbody></table><p>五种数据结构</p><p>Redis中会根据存储的数据类型不同，选择不同的编码方式。每种数据类型的使用的编码方式如下：</p><table><thead><tr><th><strong>数据类型</strong></th><th><strong>编码方式</strong></th></tr></thead><tbody><tr><td>OBJ_STRING</td><td>int、embstr、raw</td></tr><tr><td>OBJ_LIST</td><td>LinkedList和ZipList(3.2以前)、QuickList（3.2以后）</td></tr><tr><td>OBJ_SET</td><td>intset、HT</td></tr><tr><td>OBJ_ZSET</td><td>ZipList、HT、SkipList</td></tr><tr><td>OBJ_HASH</td><td>ZipList、HT</td></tr></tbody></table><h3 id="redis数据结构-string" tabindex="-1"><a class="header-anchor" href="#redis数据结构-string" aria-hidden="true">#</a> Redis数据结构-String</h3><p>String是Redis中最常见的数据存储类型：</p><p>其基本编码方式是RAW，基于简单动态字符串（SDS）实现，存储上限为512mb。</p><p>如果存储的SDS长度小于44字节，则会采用EMBSTR编码，此时object head与SDS是一段连续空间。申请内存时</p><p>只需要调用一次内存分配函数，效率更高。</p><p>（1）底层实现⽅式：动态字符串sds 或者 long String的内部存储结构⼀般是sds（Simple Dynamic String，可以动态扩展内存），但是如果⼀个String类型的value的值是数字，那么Redis内部会把它转成long类型来存储，从⽽减少内存的使用。</p><p>确切地说，String在Redis中是⽤⼀个robj来表示的。</p><p>如果存储的字符串是整数值，并且大小在LONG_MAX范围内，则会采用INT编码：直接将数据保存在RedisObject的ptr指针位置（刚好8字节），不再需要SDS了。</p><p>用来表示String的robj可能编码成3种内部表⽰：OBJ_ENCODING_RAW，OBJ_ENCODING_EMBSTR，OBJ_ENCODING_INT。 其中前两种编码使⽤的是sds来存储，最后⼀种OBJ_ENCODING_INT编码直接把string存成了long型。<br> 在对string进行incr, decr等操作的时候，如果它内部是OBJ_ENCODING_INT编码，那么可以直接行加减操作；如果它内部是OBJ_ENCODING_RAW或OBJ_ENCODING_EMBSTR编码，那么Redis会先试图把sds存储的字符串转成long型，如果能转成功，再进行加减操作。对⼀个内部表示成long型的string执行append, setbit, getrange这些命令，针对的仍然是string的值（即⼗进制表示的字符串），而不是针对内部表⽰的long型进⾏操作。比如字符串”32”，如果按照字符数组来解释，它包含两个字符，它们的ASCII码分别是0x33和0x32。当我们执行命令setbit key 7 0的时候，相当于把字符0x33变成了0x32，这样字符串的值就变成了”22”。⽽如果将字符串”32”按照内部的64位long型来解释，那么它是0x0000000000000020，在这个基础上执⾏setbit位操作，结果就完全不对了。因此，在这些命令的实现中，会把long型先转成字符串再进行相应的操作。</p><h3 id="redis数据结构-list" tabindex="-1"><a class="header-anchor" href="#redis数据结构-list" aria-hidden="true">#</a> Redis数据结构-List</h3><p>Redis的List类型可以从首、尾操作列表中的元素：</p><p>哪一个数据结构能满足上述特征？</p><ul><li>LinkedList ：普通链表，可以从双端访问，内存占用较高，内存碎片较多</li><li>ZipList ：压缩列表，可以从双端访问，内存占用低，存储上限低</li><li>QuickList：LinkedList + ZipList，可以从双端访问，内存占用较低，包含多个ZipList，存储上限高</li></ul><p>Redis的List结构类似一个双端链表，可以从首、尾操作列表中的元素：</p><p>在3.2版本之前，Redis采用ZipList和LinkedList来实现List，当元素数量小于512并且元素大小小于64字节时采用ZipList编码，超过则采用LinkedList编码。</p><p>在3.2版本之后，Redis统一采用QuickList来实现List：</p>',22),bi=["src"],gi=a('<h3 id="redis数据结构-set结构" tabindex="-1"><a class="header-anchor" href="#redis数据结构-set结构" aria-hidden="true">#</a> Redis数据结构-Set结构</h3><p>Set是Redis中的单列集合，满足下列特点：</p><ul><li>不保证有序性</li><li>保证元素唯一</li><li>求交集、并集、差集</li></ul><p>可以看出，Set对查询元素的效率要求非常高，思考一下，什么样的数据结构可以满足？<br> HashTable，也就是Redis中的Dict，不过Dict是双列集合（可以存键、值对）</p><p>Set是Redis中的集合，不一定确保元素有序，可以满足元素唯一、查询效率要求极高。<br> 为了查询效率和唯一性，set采用HT编码（Dict）。Dict中的key用来存储元素，value统一为null。<br> 当存储的所有数据都是整数，并且元素数量不超过set-max-intset-entries时，Set会采用IntSet编码，以节省内存</p><h3 id="redis数据结构-zset" tabindex="-1"><a class="header-anchor" href="#redis数据结构-zset" aria-hidden="true">#</a> Redis数据结构-ZSET</h3><p>ZSet也就是SortedSet，其中每一个元素都需要指定一个score值和member值：</p><ul><li>可以根据score值排序后</li><li>member必须唯一</li><li>可以根据member查询分数</li></ul><p>因此，zset底层数据结构必须满足键值存储、键必须唯一、可排序这几个需求。之前学习的哪种编码结构可以满足？</p><ul><li>SkipList：可以排序，并且可以同时存储score和ele值（member）</li><li>HT（Dict）：可以键值存储，并且可以根据key找value</li></ul><p>当元素数量不多时，HT和SkipList的优势不明显，而且更耗内存。因此zset还会采用ZipList结构来节省内存，不过需要同时满足两个条件：</p><ul><li>元素数量小于zset_max_ziplist_entries，默认值128</li><li>每个元素都小于zset_max_ziplist_value字节，默认值64</li></ul><p>ziplist本身没有排序功能，而且没有键值对的概念，因此需要有zset通过编码实现：</p><ul><li>ZipList是连续内存，因此score和element是紧挨在一起的两个entry， element在前，score在后</li><li>score越小越接近队首，score越大越接近队尾，按照score值升序排列</li></ul><h3 id="redis数据结构-hash" tabindex="-1"><a class="header-anchor" href="#redis数据结构-hash" aria-hidden="true">#</a> Redis数据结构-Hash</h3><p>Hash结构与Redis中的Zset非常类似：</p><ul><li>都是键值存储</li><li>都需求根据键获取值</li><li>键必须唯一</li></ul><p>区别如下：</p><ul><li>zset的键是member，值是score；hash的键和值都是任意值</li><li>zset要根据score排序；hash则无需排序</li></ul><p>（1）底层实现方式：压缩列表ziplist 或者 字典dict 当Hash中数据项比较少的情况下，Hash底层才⽤压缩列表ziplist进⾏存储数据，随着数据的增加，底层的ziplist就可能会转成dict，具体配置如下：</p><p>hash-max-ziplist-entries 512</p><p>hash-max-ziplist-value 64</p><p>当满足上面两个条件其中之⼀的时候，Redis就使⽤dict字典来实现hash。 Redis的hash之所以这样设计，是因为当ziplist变得很⼤的时候，它有如下几个缺点：</p><ul><li>每次插⼊或修改引发的realloc操作会有更⼤的概率造成内存拷贝，从而降低性能。</li><li>⼀旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更⼤的⼀块数据。</li><li>当ziplist数据项过多的时候，在它上⾯查找指定的数据项就会性能变得很低，因为ziplist上的查找需要进行遍历。</li></ul><p>总之，ziplist本来就设计为各个数据项挨在⼀起组成连续的内存空间，这种结构并不擅长做修改操作。⼀旦数据发⽣改动，就会引发内存realloc，可能导致内存拷贝。</p><p>因此，Hash底层采用的编码与Zset也基本一致，只需要把排序有关的SkipList去掉即可：</p><p>Hash结构默认采用ZipList编码，用以节省内存。 ZipList中相邻的两个entry 分别保存field和value</p><p>当数据量较大时，Hash结构会转为HT编码，也就是Dict，触发条件有两个：</p><ul><li>ZipList中的元素数量超过了hash-max-ziplist-entries（默认512）</li><li>ZipList中的任意entry大小超过了hash-max-ziplist-value（默认64字节）</li></ul><h2 id="线程" tabindex="-1"><a class="header-anchor" href="#线程" aria-hidden="true">#</a> 线程</h2><p><strong>Redis到底是单线程还是多线程？</strong></p><ul><li>如果仅仅聊Redis的核心业务部分（命令处理），答案是单线程</li><li>如果是聊整个Redis，那么答案就是多线程</li></ul><p>在Redis版本迭代过程中，在两个重要的时间节点上引入了多线程的支持：</p><ul><li>Redis v4.0：引入多线程异步处理一些耗时较旧的任务，例如异步删除命令unlink</li><li>Redis v6.0：在核心网络模型中引入 多线程，进一步提高对于多核CPU的利用率</li></ul><h3 id="为什么redis要选择单线程" tabindex="-1"><a class="header-anchor" href="#为什么redis要选择单线程" aria-hidden="true">#</a> 为什么Redis要选择单线程</h3><ul><li>抛开持久化不谈，Redis是纯 内存操作，执行速度非常快，它的性能瓶颈是网络延迟而不是执行速度，因此多线程并不会带来巨大的性能提升。</li><li>多线程会导致过多的上下文切换，带来不必要的开销</li><li>引入多线程会面临线程安全问题，必然要引入线程锁这样的安全手段，实现复杂度增高，而且性能也会大打折扣</li></ul><h2 id="redis通信协议-resp协议" tabindex="-1"><a class="header-anchor" href="#redis通信协议-resp协议" aria-hidden="true">#</a> Redis通信协议-RESP协议</h2><p>Redis是一个CS架构的软件，通信一般分两步（不包括pipeline和PubSub）：</p><p>客户端（client）向服务端（server）发送一条命令</p><p>服务端解析并执行命令，返回响应结果给客户端</p><p>因此客户端发送命令的格式、服务端响应结果的格式必须有一个规范，这个规范就是通信协议。</p><p>而在Redis中采用的是RESP（Redis Serialization Protocol）协议：</p><p>Redis 1.2版本引入了RESP协议</p><p>Redis 2.0版本中成为与Redis服务端通信的标准，称为RESP2</p><p>Redis 6.0版本中，从RESP2升级到了RESP3协议，增加了更多数据类型并且支持6.0的新特性--客户端缓存</p><p>但目前，默认使用的依然是RESP2协议，也是我们要学习的协议版本（以下简称RESP）。</p><p>在RESP中，通过首字节的字符来区分不同数据类型，常用的数据类型包括5种：</p><p>单行字符串：首字节是 ‘+’ ，后面跟上单行字符串，以CRLF（ &quot;\\r\\n&quot; ）结尾。例如返回&quot;OK&quot;： &quot;+OK\\r\\n&quot;</p><p>错误（Errors）：首字节是 ‘-’ ，与单行字符串格式一样，只是字符串是异常信息，例如：&quot;-Error message\\r\\n&quot;</p><p>数值：首字节是 ‘:’ ，后面跟上数字格式的字符串，以CRLF结尾。例如：&quot;:10\\r\\n&quot;</p><p>多行字符串：首字节是 ‘$’ ，表示二进制安全的字符串，最大支持512MB：</p><p>如果大小为0，则代表空字符串：&quot;$0\\r\\n\\r\\n&quot;</p><p>如果大小为-1，则代表不存在：&quot;$-1\\r\\n&quot;</p><p>数组：首字节是 ‘*’，后面跟上数组元素个数，再跟上元素，元素数据类型不限:</p>',54),mi=["src"],_i=e("h2",{id:"redis内存回收-过期key处理",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#redis内存回收-过期key处理","aria-hidden":"true"},"#"),s(" Redis内存回收-过期key处理")],-1),ki=e("p",null,"Redis之所以性能强，最主要的原因就是基于内存存储。然而单节点的Redis其内存大小不宜过大，会影响持久化或主从同步性能。 我们可以通过修改配置文件来设置Redis的最大内存：",-1),Ri=["src"],yi=a('<p>内存使用达到上限时，就无法存储更多数据了。为了解决这个问题，Redis提供了一些策略实现内存回收：</p><p>内存过期策略</p><p>在学习Redis缓存的时候我们说过，可以通过expire命令给Redis的key设置TTL（存活时间）：</p><p><strong>惰性删除</strong></p><p>惰性删除：顾明思议并不是在TTL到期后就立刻删除，而是在访问一个key的时候，检查该key的存活时间，如果已经过期才执行删除。</p><p><strong>周期删除</strong></p><p>周期删除：顾明思议是通过一个定时任务，周期性的抽样部分过期的key，然后执行删除。执行周期有两种： Redis服务初始化函数initServer()中设置定时任务，按照server.hz的频率来执行过期key清理，模式为SLOW Redis的每个事件循环前会调用beforeSleep()函数，执行过期key清理，模式为FAST</p><p>周期删除：顾明思议是通过一个定时任务，周期性的抽样部分过期的key，然后执行删除。执行周期有两种： Redis服务初始化函数initServer()中设置定时任务，按照server.hz的频率来执行过期key清理，模式为SLOW Redis的每个事件循环前会调用beforeSleep()函数，执行过期key清理，模式为FAST</p><p>SLOW模式规则：</p><ul><li>执行频率受server.hz影响，默认为10，即每秒执行10次，每个执行周期100ms。</li><li>执行清理耗时不超过一次执行周期的25%.默认slow模式耗时不超过25ms</li><li>逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期</li><li>如果没达到时间上限（25ms）并且过期key比例大于10%，再进行一次抽样，否则结束</li><li>FAST模式规则（过期key比例小于10%不执行 ）：</li><li>执行频率受beforeSleep()调用频率影响，但两次FAST模式间隔不低于2ms</li><li>执行清理耗时不超过1ms</li><li>逐个遍历db，逐个遍历db中的bucket，抽取20个key判断是否过期 如果没达到时间上限（1ms）并且过期key比例大于10%，再进行一次抽样，否则结束</li></ul><p>小总结：</p><p>RedisKey的TTL记录方式：</p><p>在RedisDB中通过一个Dict记录每个Key的TTL时间</p><p>过期key的删除策略：</p><p>惰性清理：每次查找key时判断是否过期，如果过期则删除</p><p>定期清理：定期抽样部分key，判断是否过期，如果过期则删除。 定期清理的两种模式：</p><p>SLOW模式执行频率默认为10，每次不超过25ms</p><p>FAST模式执行频率不固定，但两次间隔不低于2ms，每次耗时不超过1ms</p><h2 id="redis内存回收-内存淘汰策略" tabindex="-1"><a class="header-anchor" href="#redis内存回收-内存淘汰策略" aria-hidden="true">#</a> Redis内存回收-内存淘汰策略</h2><p>内存淘汰：就是当Redis内存使用达到设置的上限时，主动挑选部分key删除以释放更多内存的流程。Redis会在处理客户端命令的方法processCommand()中尝试做内存淘汰：</p><p>淘汰策略</p><p>Redis支持8种不同策略来选择要删除的key：</p><ul><li>noeviction： 不淘汰任何key，但是内存满时不允许写入新数据，默认就是这种策略。</li><li>volatile-ttl： 对设置了TTL的key，比较key的剩余TTL值，TTL越小越先被淘汰</li><li>allkeys-random：对全体key ，随机进行淘汰。也就是直接从db-&gt;dict中随机挑选</li><li>volatile-random：对设置了TTL的key ，随机进行淘汰。也就是从db-&gt;expires中随机挑选。</li><li>allkeys-lru： 对全体key，基于LRU算法进行淘汰</li><li>volatile-lru： 对设置了TTL的key，基于LRU算法进行淘汰</li><li>allkeys-lfu： 对全体key，基于LFU算法进行淘汰</li><li>volatile-lfu： 对设置了TTL的key，基于LFI算法进行淘汰 比较容易混淆的有两个： <ul><li>LRU（Least Recently Used），最少最近使用。用当前时间减去最后一次访问时间，这个值越大则淘汰优先级越高。</li><li>LFU（Least Frequently Used），最少频率使用。会统计每个key的访问频率，值越小淘汰优先级越高。</li></ul></li></ul>',23);function Si(i,fi){return r(),l("div",null,[d,e("img",{src:i.$withBase("/images/redis/18.png"),alt:"redis"},null,8,p),h,e("p",null,[s("Redis中的HLL是基于string结构实现的，单个HLL的内存永远小于16kb，内存占用低的令人发指！作为代价，其测量结果是概率性的，有小于0.81％的误差。不过对于UV统计来说，这完全可以忽略。"),o,e("img",{src:i.$withBase("/images/redis/19.png"),alt:"redis"},null,8,c)]),u,b,g,e("img",{src:i.$withBase("/images/redis/1.png"),alt:"redis"},null,8,m),_,e("img",{src:i.$withBase("/images/redis/2.png"),alt:"redis"},null,8,k),R,y,e("img",{src:i.$withBase("/images/redis/3.png"),alt:"redis"},null,8,S),e("img",{src:i.$withBase("/images/redis/4.png"),alt:"redis"},null,8,f),e("img",{src:i.$withBase("/images/redis/5.png"),alt:"redis"},null,8,B),v,L,e("img",{src:i.$withBase("/images/redis/6.png"),alt:"redis"},null,8,O),T,e("img",{src:i.$withBase("/images/redis/7.png"),alt:"redis"},null,8,E),D,e("img",{src:i.$withBase("/images/redis/8.png"),alt:"redis"},null,8,w),x,I,e("img",{src:i.$withBase("/images/redis/9.png"),alt:"redis"},null,8,N),$,e("img",{src:i.$withBase("/images/redis/10.png"),alt:"redis"},null,8,A),P,e("img",{src:i.$withBase("/images/redis/11.png"),alt:"redis"},null,8,H),e("img",{src:i.$withBase("/images/redis/12.png"),alt:"redis"},null,8,Z),G,C,e("img",{src:i.$withBase("/images/redis/13.png"),alt:"redis"},null,8,q),e("img",{src:i.$withBase("/images/redis/14.png"),alt:"redis"},null,8,F),M,e("img",{src:i.$withBase("/images/redis/15.png"),alt:"redis"},null,8,K),e("img",{src:i.$withBase("/images/redis/16.png"),alt:"redis"},null,8,z),e("img",{src:i.$withBase("/images/redis/17.png"),alt:"redis"},null,8,J),U,j,e("img",{src:i.$withBase("/images/redis/20.png"),alt:"redis"},null,8,Q),V,e("img",{src:i.$withBase("/images/redis/21.png"),alt:"redis"},null,8,W),Y,e("img",{src:i.$withBase("/images/redis/24.png"),alt:"redis"},null,8,X),ee,ie,e("p",null,[s("3.执行bgsave命令"),se,s(" gsave命令是对save命令的一个优化，是一个异步操作。执行该命令后，redis主进程会通过fork操作创建一个子进程，RDB持久化是由子进程操作，完成后自动结束。这个过程中，主进程不阻塞，可以继续接收客户端的访问。因此，redis内部所有涉及RDB持久化的操作都是采用的bgsave方式，save命令基本已经废弃。"),ae,e("img",{src:i.$withBase("/images/redis/25.png"),alt:"redis"},null,8,te)]),re,le,ne,de,pe,he,e("img",{src:i.$withBase("/images/redis/30.png"),alt:"redis"},null,8,oe),ce,ue,be,ge,me,e("img",{src:i.$withBase("/images/redis/26.png"),alt:"redis"},null,8,_e),ke,e("img",{src:i.$withBase("/images/redis/27.png"),alt:"redis"},null,8,Re),ye,e("img",{src:i.$withBase("/images/redis/28.png"),alt:"redis"},null,8,Se),e("img",{src:i.$withBase("/images/redis/29.png"),alt:"redis"},null,8,fe),Be,ve,e("img",{src:i.$withBase("/images/redis/22.png"),alt:"redis"},null,8,Le),Oe,e("img",{src:i.$withBase("/images/redis/31.png"),alt:"redis"},null,8,Te),Ee,De,we,e("img",{src:i.$withBase("/images/redis/32.png"),alt:"redis"},null,8,xe),e("img",{src:i.$withBase("/images/redis/33.png"),alt:"redis"},null,8,Ie),e("img",{src:i.$withBase("/images/redis/34.png"),alt:"redis"},null,8,Ne),$e,e("img",{src:i.$withBase("/images/redis/35.png"),alt:"redis"},null,8,Ae),Pe,e("img",{src:i.$withBase("/images/redis/36.png"),alt:"redis"},null,8,He),Ze,e("img",{src:i.$withBase("/images/redis/37.png"),alt:"redis"},null,8,Ge),Ce,e("img",{src:i.$withBase("/images/redis/38.png"),alt:"redis"},null,8,qe),Fe,Me,e("img",{src:i.$withBase("/images/redis/39.png"),alt:"redis"},null,8,Ke),ze,e("img",{src:i.$withBase("/images/redis/40.png"),alt:"redis"},null,8,Je),Ue,e("img",{src:i.$withBase("/images/redis/41.png"),alt:"redis"},null,8,je),Qe,e("img",{src:i.$withBase("/images/redis/42.png"),alt:"redis"},null,8,Ve),We,Ye,Xe,e("img",{src:i.$withBase("/images/redis/43.png"),alt:"redis"},null,8,ei),ii,e("img",{src:i.$withBase("/images/redis/44.png"),alt:"redis"},null,8,si),ai,e("img",{src:i.$withBase("/images/redis/45.png"),alt:"redis"},null,8,ti),ri,e("img",{src:i.$withBase("/images/redis/46.png"),alt:"redis"},null,8,li),e("img",{src:i.$withBase("/images/redis/47.png"),alt:"redis"},null,8,ni),di,e("img",{src:i.$withBase("/images/redis/48.png"),alt:"redis"},null,8,pi),e("img",{src:i.$withBase("/images/redis/49.png"),alt:"redis"},null,8,hi),oi,e("img",{src:i.$withBase("/images/redis/50.png"),alt:"redis"},null,8,ci),ui,e("img",{src:i.$withBase("/images/redis/51.png"),alt:"redis"},null,8,bi),gi,e("img",{src:i.$withBase("/images/redis/52.png"),alt:"redis"},null,8,mi),_i,ki,e("img",{src:i.$withBase("/images/redis/53.png"),alt:"redis"},null,8,Ri),yi])}const vi=t(n,[["render",Si],["__file","redis.html.vue"]]);export{vi as default};
